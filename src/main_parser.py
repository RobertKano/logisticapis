# -*- coding: utf-8 -*-
# Copyright (C) 2024-2026 RobertKano
# Project: LogisticAPIs (https://github.com)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org>.


import time
import json
import os
import re
from datetime import datetime

import settings as st


def cleanup_old_reports(data_dir, days=14):
    """–£–¥–∞–ª—è–µ—Ç –æ—Ç—á–µ—Ç—ã —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ö–ª–∞–º–ª—è—Ç—å –¥–∏—Å–∫"""
    if not os.path.exists(data_dir):
        return

    now = time.time()
    cutoff = now - (days * 86400) # 86400 —Å–µ–∫—É–Ω–¥ –≤ —Å—É—Ç–∫–∞—Ö
    deleted_count = 0

    for f in os.listdir(data_dir):
        # –ú–∞—Å–∫–∞ —Ñ–∞–π–ª–∞: —Å—Ç—Ä–æ–≥–æ report_YYYY-MM-DD.json
        if f.startswith("report_") and f.endswith(".json"):
            file_path = os.path.join(data_dir, f)
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
                if os.stat(file_path).st_mtime < cutoff:
                    os.remove(file_path)
                    deleted_count += 1
            except Exception as e:
                print(f"[Cleanup] –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {f}: {e}")

    if deleted_count > 0:
        print(f"[Cleanup] –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –æ—Ç—á–µ—Ç–æ–≤: {deleted_count}")


def update_permanent_archive(new_archive_items):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–∫–∞–∑—ã –≤ –≤–µ—á–Ω—ã–π –∞—Ä—Ö–∏–≤, –¥–æ–ø–æ–ª–Ω—è—è –µ–≥–æ"""
    if not new_archive_items:
        return

    # 1. –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞—Ä—Ö–∏–≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ
    old_history = []
    if os.path.exists(st.HISTORY_FILE):
        try:
            with open(st.HISTORY_FILE, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content:
                    old_history = json.loads(content)
        except Exception as e:
            print(f"[Archive Error] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
            old_history = []

    # 2. –°–æ–∑–¥–∞–µ–º –Ω–∞–±–æ—Ä —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö ID –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    existing_ids = {str(item.get('id')) for item in old_history if item.get('id')}

    # 3. –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã—Ö —Ä–µ–∞–ª—å–Ω–æ –Ω–µ—Ç –≤ –±–∞–∑–µ
    added_count = 0
    for item in new_archive_items:
        cargo_id = str(item.get('id', ''))

        # –ï—Å–ª–∏ ID –ø—É—Å—Ç–æ–π (—Ç–∞–∫–æ–≥–æ –±—ã—Ç—å –Ω–µ –¥–æ–ª–∂–Ω–æ) –∏–ª–∏ —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if not cargo_id or cargo_id in existing_ids:
            continue

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è
        item['archived_at'] = datetime.now().strftime('%d.%m.%Y')
        if 'tk' not in item and item.get('is_manual'):
            item['tk'] = "üìù –ü–ê–ú–Ø–¢–ö–ê"

        old_history.append(item)
        existing_ids.add(cargo_id)
        added_count += 1

    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–ï–°–¨ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞—Ç–Ω–æ
    if added_count > 0:
        try:
            with open(st.HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(old_history, f, ensure_ascii=False, indent=4)
            print(f"[Archive] –£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {added_count}. –í—Å–µ–≥–æ –≤ –∞—Ä—Ö–∏–≤–µ: {len(old_history)}")
        except Exception as e:
            print(f"[Archive Error] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")


def clean_name(text, is_city=False):
    if not text or not isinstance(text, str): return "???"

    # 1. –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞: —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –∫–∞–≤—ã—á–∫–∏ –°–†–ê–ó–£
    cleaned = text.replace('"', '').replace('¬´', '').replace('¬ª', '').replace("'", "")
    cleaned = re.sub(r'\(.*?\)', '', cleaned).lower()

    if is_city:
        # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–∏—Å—Ç–∞–≤–∫–∏
        city_trash = ["–≥. ", "–≥–æ—Ä–æ–¥ ", "–ø–≥—Ç. ", "–ø–æ—Å–µ–ª–æ–∫ ", "–æ–±–ª–∞—Å—Ç—å", "–æ–±–ª.", " –∫—Ä–∞–π", " —Ä-–Ω", " –º–æ", " –≥ "]
        for trash in city_trash:
            cleaned = cleaned.replace(trash, "")

        # –°–æ–∫—Ä–∞—â–∞–µ–º —Ç–µ—Ä–º–∏–Ω–∞–ª—ã –∏ —Å—Ç–æ—Ä–æ–Ω—ã —Å–≤–µ—Ç–∞
        city_replacements = {
            "–≤–æ—Å—Ç–æ–∫": "–í–°–¢", "–∑–∞–ø–∞–¥": "–ó–ü–î", "—Å–µ–≤–µ—Ä": "–°–ï–í", "—é–≥": "–Æ–ì",
            "—Ç–µ—Ä–º–∏–Ω–∞–ª": "–¢–ï–†–ú", "—Å–∫–ª–∞–¥": "–°–ö–õ", "—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π": "–¶–ï–ù–¢–†",
            "—é–≥–æ-–∑–∞–ø–∞–¥": "–Æ-–ó", "—Å–µ–≤–µ—Ä–æ-–≤–æ—Å—Ç–æ–∫": "–°-–í"
        }
        for long, short in city_replacements.items():
            cleaned = cleaned.replace(long, short)

        # –ú–∞–ø–ø–∏–Ω–≥ –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ settings.py (–ê—Å—Ç—Ä–∞—Ö–∞–Ω—å -> –ê–°–¢–†–ê –∏ —Ç.–¥.)
        for full, short in st.CITY_MAP.items():
            if full in cleaned:
                cleaned = cleaned.replace(full, short)
    else:
        # 2. –°–æ–∫—Ä–∞—â–∞–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã
        org_replacements = {
            "–æ–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é": "–û–û–û",
            "–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å": "–ò–ü",
            "–∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ": "–ê–û",
            "–ø—É–±–ª–∏—á–Ω–æ–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–æ": "–ü–ê–û",
            "—Ç–æ—Ä–≥–æ–≤—ã–π –¥–æ–º": "–¢–î",
            "–≥—Ä—É–ø–ø–∞ –∫–æ–º–ø–∞–Ω–∏–π": "–ì–ö",
            "–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ": "–ü–û"
        }
        for long, short in org_replacements.items():
            cleaned = cleaned.replace(long, short)

        # 3. –ß–∏—Å—Ç–∏–º "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —à—É–º" –≤ –∏–º–µ–Ω–∞—Ö –∫–æ–º–ø–∞–Ω–∏–π
        # (–£–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–µ—à–∞—é—Ç –±—ã—Å—Ç—Ä–æ–º—É –ø–æ–∏—Å–∫—É)
        noise_words = ["–∫–æ–º–ø–∞–Ω–∏—è", "–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è", "–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ", "–ª—Ç–¥", "ltd"]
        for word in noise_words:
            cleaned = re.sub(rf'\b{word}\b', '', cleaned)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞: —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –≤ UPPER CASE
    return " ".join(cleaned.split()).strip().upper()


# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –¢–ö ---

def parse_baikal(data):
    # –ï—Å–ª–∏ –ø—Ä–∏—à–µ–ª –Ω–µ —Å–ø–∏—Å–æ–∫ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if not data or not isinstance(data, list):
        return []

    results = []
    for order in data:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≥–ª—É—à–∫–∞ –ª–∏ —ç—Ç–æ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
        if order.get("status") == "empty":
            continue

        cargo_list = order.get("cargoList", [])
        if not cargo_list: continue

        first_item = cargo_list[0]
        consignor = first_item.get("consignor", {})
        consignee = first_item.get("consignee", {})

        services = first_item.get("services", [])
        payer_data = services[0].get("payer", {}) if services else {}
        payer_inn = payer_data.get("inn")

        if payer_inn == consignee.get("inn"):
            payer_type = "recipient"
        elif payer_inn == consignor.get("inn"):
            payer_type = "sender"
        else:
            payer_type = "third_party"

        # –°—á–∏—Ç–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        places = sum(int(item.get("cargo", {}).get("places") or 0) for item in cargo_list)
        weight = sum(float(item.get("cargo", {}).get("weight") or 0) for item in cargo_list)
        volume = sum(float(item.get("cargo", {}).get("volume") or 0) for item in cargo_list)

        # —Ä–∞—Å—á–µ—Ç –¥–æ–ª–≥–∞ –∏ –æ–ø–ª–∞—Ç—ã
        total = order.get("total") or first_item.get("total", {})
        total_sum = float(total.get("sum") or 0)
        total_paid = float(total.get("paid") or 0)
        debt = round(total_sum - total_paid, 2)

        if debt > 0:
            payment_status = f"–ö –û–ü–õ–ê–¢–ï: {debt}"
        else:
            payment_status = order.get("paidStatus") or "–ù/–î"

        results.append({
            "tk": "–ë–∞–π–∫–∞–ª –°–µ—Ä–≤–∏—Å",
            "id": order.get("tracking") or "–ù/–î",
            "sender": clean_name(consignor.get("name")),
            "recipient": clean_name(consignee.get("name")),
            "payer_type": payer_type,
            "status": order.get("orderstatus", "–ù/–î"),
            "params": f"{places}–º | {weight}–∫–≥ | {volume}–º3",
            "arrival": first_item.get('dateArrivalPlane') or order.get('dateArrivalPlane'),
            "payment": payment_status,
            "route": f"{clean_name(first_item.get('departure', {}).get('name'), True)} ‚û°Ô∏è {clean_name(first_item.get('destination', {}).get('name'), True)}"
        })
    return results

def parse_dellin(data):
    results = []
    for o in data.get("orders", []):
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç (–Ω–∞–∫–ª–∞–¥–Ω—É—é)
        docs = o.get("documents", [])
        main_doc = docs[0] if docs else {}

        f = o.get("freight", {})
        sender_data = o.get("sender", {})
        receiver_data = o.get("receiver", {})
        payer_data = o.get("payer", {})

        # --- –õ–û–ì–ò–ö–ê –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –°–¢–ê–¢–£–°–ê –û–ü–õ–ê–¢–´ ---
        # –£ –î–õ –µ—Å—Ç—å –ø–æ–ª–µ isPaid –≤ –∫–æ—Ä–Ω–µ, –Ω–æ –¥–æ–ª–≥ —Ç–æ—á–Ω–µ–µ –≤ main_doc
        debt = float(main_doc.get("debtSum") or 0)
        is_paid_root = o.get("isPaid", False)

        if debt > 0:
            payment_status = f"–ö –û–ü–õ–ê–¢–ï: {debt}"
        elif is_paid_root:
            payment_status = "–û–ø–ª–∞—á–µ–Ω–æ"
        else:
            # –ï—Å–ª–∏ –¥–æ–ª–≥ 0, –Ω–æ —Ñ–ª–∞–≥ isPaid=False ‚Äî –∑–Ω–∞—á–∏—Ç, —Å—á–µ—Ç –µ—â–µ –Ω–µ –∑–∞–∫—Ä—ã—Ç (–∂–¥–µ–º –ø—Ä–æ–≤–æ–¥–∫—É)
            total_sum = main_doc.get("totalSum") or o.get("totalSum", "–ù/–î")
            payment_status = f"–ö –û–ü–õ–ê–¢–ï: {total_sum}"
        # ------------------------------------------

        p_inn = payer_data.get("inn")
        r_inn = receiver_data.get("inn")

        if p_inn and r_inn and p_inn == r_inn:
            payer_type = "recipient"
        elif p_inn and p_inn == sender_data.get("inn"):
            payer_type = "sender"
        else:
            payer_type = "third_party"

        results.append({
            "tk": "–î–µ–ª–æ–≤—ã–µ –õ–∏–Ω–∏–∏",
            "id": o.get("orderId"),
            "sender": clean_name(sender_data.get("name")),
            "recipient": clean_name(receiver_data.get("name")),
            "payer_type": payer_type,
            "status": f"{o.get('stateName')} ({o.get('progressPercent')}%)",
            "params": f"{f.get('places')}–º | {f.get('weight')}–∫–≥ | {f.get('volume')}–º3",
            "arrival": o.get("orderDates", {}).get("arrivalToOspReceiver"),
            "payment": payment_status, # –ó–ê–ú–ï–ù–ï–ù–û
            "route": f"{clean_name(o.get('derival', {}).get('terminalCity') or o.get('derival', {}).get('city'), True)} ‚û°Ô∏è {clean_name(o.get('arrival', {}).get('terminalCity') or o.get('arrival', {}).get('city'), True)}"
        })
    return results



def parse_pecom(data):
    results = []
    for i in data.get("cargos", []):
        c = i.get("cargo", {})
        info = i.get("info", {})
        services = i.get("services", {})
        service_items = services.get("items", [])

        # 1. –°–£–ú–ú–ê–†–ù–´–ô –î–û–õ–ì (–≥–ª–∞–≤–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å)
        total_debt = float(services.get("debt", 0))

        # 2. –ü–†–û–í–ï–†–ö–ê –ü–û –í–°–ï–ú –£–°–õ–£–ì–ê–ú (—á–µ—Ä–µ–∑ any)
        # –ò—â–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—å –æ–¥–Ω–∞ —É—Å–ª—É–≥–∞, –∫–æ—Ç–æ—Ä—É—é –ü–≠–ö –ø–æ–º–µ—Ç–∏–ª –∫–∞–∫ "–∫ –æ–ø–ª–∞—Ç–µ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏"
        has_unpaid_service = any(s.get("payToReceive") is True for s in service_items)

        # –ò—Ç–æ–≥–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –æ–ø–ª–∞—Ç—ã:
        if total_debt <= 0 and not has_unpaid_service:
            payment_status = "–û–ø–ª–∞—á–µ–Ω–æ"
        elif total_debt > 0 and not has_unpaid_service:
            # –ö–µ–π—Å, –∫–æ–≥–¥–∞ –¥–æ–ª–≥ –µ—Å—Ç—å, –Ω–æ –æ–Ω "–Ω–µ –±–ª–æ–∫–∏—Ä—É—é—â–∏–π" (—Ä–µ–¥–∫–æ, –Ω–æ –±—ã–≤–∞–µ—Ç)
            payment_status = f"–î–æ–ª–≥: {total_debt}"
        else:
            # –°–∞–º—ã–π –∫—Ä–∏—Ç–∏—á–Ω—ã–π —Å–ª—É—á–∞–π: –µ—Å—Ç—å —É—Å–ª—É–≥–∏, –ø–æ–º–µ—á–µ–Ω–Ω—ã–µ "–∫ –æ–ø–ª–∞—Ç–µ"
            payment_status = f"–ö –û–ü–õ–ê–¢–ï: {total_debt}"

        # ... (–ª–æ–≥–∏–∫–∞ payer_type –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–µ–π) ...
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º .all() –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è payer_type, –µ—Å–ª–∏ —Ö–æ—Ç–∏–º –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏,
        # —á—Ç–æ –ø–ª–∞—Ç–µ–ª—å—â–∏–∫ –≤–µ–∑–¥–µ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ (–æ–±—ã—á–Ω–æ —ç—Ç–æ —Ç–∞–∫)
        p_types = [s.get("payerType") for s in service_items]
        if all(pt == 2 for pt in p_types):
            payer_type = "recipient"
        elif all(pt == 1 for pt in p_types):
            payer_type = "sender"
        else:
            payer_type = "mixed/third_party"

        results.append({
            "tk": "–ü–≠–ö",
            "id": c.get("cargoBarCode"),
            "sender": clean_name(i.get("sender", {}).get("sender")),
            "recipient": clean_name(i.get("receiver", {}).get("receiver")),
            "payer_type": payer_type,
            "status": info.get("cargoStatus"),
            "params": f"{int(c.get('amount', 0))}–º | {c.get('weight')}–∫–≥ | {c.get('volume')}–º3",
            "arrival": info.get("arrivalPlanDateTime"),
            "payment": payment_status, # –ù–ê–®–ê –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê
            "route": f"{clean_name(i.get('sender', {}).get('branch'), True)} ‚û°Ô∏è {clean_name(i.get('receiver', {}).get('branch', {}).get('city'), True)}"
        })
    return results

# --- –§–£–ù–ö–¶–ò–ò –°–û–•–†–ê–ù–ï–ù–ò–Ø ---

def save_report_to_file(report_lines, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        for line in report_lines:
            f.write(line + '\n')


def save_json_report(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

# --- –û–°–ù–û–í–ù–û–ô –ü–£–õ–¨–¢ ---

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º (—É–±–µ–¥–∏—Å—å, —á—Ç–æ –æ–Ω–∏ –≤ –Ω–∞—á–∞–ª–µ –º–æ–¥—É–ª—è)

def run_main_parser():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(base_dir, '..', 'data')
    input_file = os.path.join(data_dir, 'test_all_tk.json')

    if not os.path.exists(input_file):
        return print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")

    with open(input_file, 'r', encoding='utf-8') as f:
        raw_json = json.load(f)

    raw_results = []
    # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö –¢–ö
    if "Baikal" in raw_json: raw_results.extend(parse_baikal(raw_json["Baikal"]))
    if "Dellin" in raw_json: raw_results.extend(parse_dellin(raw_json["Dellin"]))
    if "Pecom" in raw_json: raw_results.extend(parse_pecom(raw_json["Pecom"]))

    manual_file = os.path.join(data_dir, 'manual_cargo.json')
    manual_data = []
    if os.path.exists(manual_file):
        with open(manual_file, 'r', encoding='utf-8') as f:
            try:
                manual_data = json.load(f)
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–º—è—Ç–∫–∏ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–æ–≤
                raw_results.extend(manual_data)
            except: pass

    # 1. –õ–û–ì–ò–ö–ê "–ü–ê–ú–Ø–¢–ò": –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ø—Ä–æ—à–ª—ã–º –∑–∞–ø—É—Å–∫–æ–º
    current_ids = {str(r['id']) for r in raw_results}

    if os.path.exists(st.LAST_STATE_FILE):
        with open(st.LAST_STATE_FILE, 'r', encoding='utf-8') as f:
            try: last_active = json.load(f)
            except: last_active = []
    else:
        last_active = []

    # –ò—â–µ–º —Ç–µ—Ö, –∫—Ç–æ –ø—Ä–æ–ø–∞–ª –∏–∑ API (–∑–Ω–∞—á–∏—Ç, –≤—ã–¥–∞–ª–∏ –∏–ª–∏ —É–¥–∞–ª–∏–ª–∏)
    missing_items = []
    for item in last_active:
        if str(item['id']) not in current_ids:
            item['status'] = "–í—ã–¥–∞–Ω (–∞–≤—Ç–æ–∞—Ä—Ö–∏–≤)"
            missing_items.append(item)

    # 2. –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –¢–ï–ö–£–©–ò–•
    EXCLUDE = ["–≤—ã–¥–∞–Ω", "–¥–æ—Å—Ç–∞–≤–ª–µ–Ω", "–∑–∞–≤–µ—Ä—à–µ–Ω", "–∞—Ä—Ö–∏–≤", "–≤—ã–¥–∞—á–∞", "–ø–æ–ª—É—á–µ–Ω"]

    active = sorted(
        [r for r in raw_results if not any(k in str(r.get('status', '')).lower() for k in EXCLUDE)],
        key=lambda x: str(x.get('arrival') or "9999")
    )

    # –ó–∞–∫–∞–∑—ã (–≤–∫–ª—é—á–∞—è –ø–∞–º—è—Ç–∫–∏), –∫–æ—Ç–æ—Ä—ã–µ –ü–†–Ø–ú–û –°–ï–ô–ß–ê–° –∏–º–µ—é—Ç —Å—Ç–∞—Ç—É—Å "–í—ã–¥–∞–Ω"
    just_finished_api = [r for r in raw_results if any(k in str(r.get('status', '')).lower() for k in EXCLUDE)]


    # 3. –ê–†–•–ò–í–ê–¶–ò–Ø (–û–±—ä–µ–¥–∏–Ω—è–µ–º —è–≤–Ω–æ –≤—ã–¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–æ–ø–∞–≤—à–∏–µ –∏–∑ —ç—Ñ–∏—Ä–∞)
    to_archive = just_finished_api + missing_items
    update_permanent_archive(to_archive)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π –∞–∫—Ç–∏–≤ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    with open(st.LAST_STATE_FILE, 'w', encoding='utf-8') as f:
        json.dump(active, f, ensure_ascii=False, indent=4)

    # 4. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –§–†–û–ù–¢–ï–ù–î–ê
    full_history = []
    if os.path.exists(st.HISTORY_FILE):
        with open(st.HISTORY_FILE, 'r', encoding='utf-8') as f:
            try:
                full_history = json.load(f)
                # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Å –∑–∞—â–∏—Ç–æ–π: –µ—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ—Ç, —Å—Ç–∞–≤–∏–º –æ—á–µ–Ω—å —Å—Ç–∞—Ä—É—é
                full_history.sort(
                    key=lambda x: datetime.strptime(x.get('archived_at', '01.01.2020'), '%d.%m.%Y'),
                    reverse=True
                )
            except Exception as e:
                print(f"[Error] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è/—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
                # –ï—Å–ª–∏ —É–ø–∞–ª–∏ ‚Äî –≤—Å—ë —Ä–∞–≤–Ω–æ –±–µ—Ä–µ–º —Ç–æ, —á—Ç–æ –ø—Ä–æ—á–∏—Ç–∞–ª–∏, –∏–ª–∏ —Ö–æ—Ç—è –±—ã –Ω–æ–≤—ã–µ
                if not full_history:
                    full_history = to_archive
    else:
        full_history = to_archive

    report_time = datetime.now().strftime('%d.%m.%Y %H:%M:%S')
    json_data = {
        "metadata": {
            "created_at": report_time,
            "active_count": len(active),
            "archive_count": len(full_history)
        },
        "active": active,
        "archive": full_history
    }

    # 5. –ö–û–ù–°–û–õ–¨–ù–´–ô –í–´–í–û–î (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–≤–æ–¥–∫—É)
    print(f"\n–û–¢–ß–ï–¢ –¢–†–ê–ù–°–ü–û–†–¢ | {report_time}")
    print("="*150)
    head = f"{'–¢–ö':<15} | {'‚Ññ –ù–∞–∫–ª–∞–¥–Ω–æ–π':<18} | {'–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å':<20} | {'–ú–∞—Ä—à—Ä—É—Ç':<25} | {'–°—Ç–∞—Ç—É—Å':<30} | {'–ü—Ä–∏–±—ã—Ç–∏–µ':<10}"
    print(head)
    print("-"*150)
    for r in active:
        line = (f"{r['tk']:<15} | {str(r['id']):<18} | {str(r['sender'])[:19]:<20} | "
                f"{str(r['route'])[:24]:<25} | {str(r['status'])[:29]:<30} | {str(r['arrival'] or '–ù/–î')[:10]:<10}")
        print(line)

    # --- –ù–û–í–û–ï: –ß–ò–°–¢–ò–ú –ü–ê–ú–Ø–¢–ö–ò, –ö–û–¢–û–†–´–ï –£–®–õ–ò –í –ê–†–•–ò–í ---
    if manual_data:
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –ø–∞–º—è—Ç–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –ø–æ–ø–∞–ª–∏ –≤ —Å–ø–∏—Å–æ–∫ "–Ω–∞ –≤—ã–ª–µ—Ç"
        active_ids = {str(a['id']) for a in active}
        remaining_manual = [m for m in manual_data if str(m['id']) in active_ids]

        with open(manual_file, 'w', encoding='utf-8') as f:
            json.dump(remaining_manual, f, ensure_ascii=False, indent=4)
        print(f"[Manual] –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û—Å—Ç–∞–ª–æ—Å—å —Ä—É—á–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(remaining_manual)}")

    # 6. –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ß–ï–¢–û–í
    date_str = datetime.now().strftime('%Y-%m-%d')

    # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á–µ—Ç –¥–ª—è –ø—Ä–æ–¥–∞ (—Å –¥–∞—Ç–æ–π)
    save_json_report(json_data, os.path.join(data_dir, f"report_{date_str}.json"))

    # –û—Ç—á–µ—Ç –¥–ª—è DEV-—Å–µ—Ä–≤–µ—Ä–∞ (–≤—Å–µ–≥–¥–∞ —Å–≤–µ–∂–∏–π —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∞–π–ª)
    save_json_report(json_data, os.path.join(data_dir, "test_all_tk_processed.json"))

    cleanup_old_reports(data_dir, days=14)

    print(f"\n[‚úì] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ê–∫—Ç–∏–≤–Ω–æ: {len(active)}, –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∞—Ä—Ö–∏–≤: {len(to_archive)}")




if __name__ == "__main__":
    run_main_parser()
